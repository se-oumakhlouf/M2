# TP 05

</br>

- ## 1 : Partionnement avec RDD

    - 1.1 :

    ```scala
    def generateData(nbTuples: Int = 1000000, uniqueKeys: Int = 1000, partitions: Int = 4) = {
        val rawData = 0 until nbTuples
        val rddBase = sc.parallelize(rawData, partitions)
        rddBase.map { i =>
            val key = scala.util.Random.nextInt(uniqueKeys)
            val value = s"Value $i"
            (key, value)
        }
    }
    ```

    - 1.2 : Scénario 1: partitionnement par défaut
    ```scala
    val rddA = generateData()
    val rddB = generateData()

    val t0 = System.nanoTime()
    val count = rddA.join(rddB).count() // Action qui déclenche le Job
    val t1 = System.nanoTime()

    println(s"Temps: ${(t1 - t0) / 1e9} s") // 14,6 s
    println(s"Nombre de lignes jointes: $count") // 999_964_795 lignes

    val occurrencesA = rddA.map { case (key, value) => (key, 1) }.reduceByKey(_ + _)
    occurrencesA.take(15).foreach(println)

    val distribution = rddA.mapPartitionsWithIndex { (index, iterator) =>
        val count = iterator.length
        Iterator((index, count)) 
    }.collect()

    println("\nDistribution des tuples parmi les partitions :")
    distribution.foreach { case (partId, count) =>
        println(s"Partition $partId : $count tuples")
    } // 250_000 tuples par partitions
    ```

    - 1.3 : Scénario 2 : partitionnement spécifique
    ```scala
    //
    ```

- ## 2 : Partionnement avec DataFrame

    - 2.1 : 
    ```scala
    val DEFAULT_PARTITIONS: Int = 4
    val dfA = rddA.toDF("key", "value_a").repartition(DEFAULT_PARTITIONS)
    val dfB = rddB.toDF("key", "value_a").repartition(DEFAULT_PARTITIONS)

    println(s"DF A a ${dfA.rdd.getNumPartitions} partitions initiales") // 4
    println(s"DF B a ${dfB.rdd.getNumPartitions} partitions initiales") // 4

    val joinDF = dfA.join(dfB)
    ```

    - 2.2 : 
    ```scala
    val dfAOpt = dfA.repartition(DEFAULT_PARTITIONS, col("key"))
    val dfBOpt = dfB.repartition(DEFAULT_PARTITIONS, col("key"))
    val joinDFOpt = dfAOpt.join(dfBOpt)
    joinDFOpt.count()
    ```


