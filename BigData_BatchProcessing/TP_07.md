# TP 07 : Hints

```scala
// Q.0 : initialisation
import org.apache.spark.sql._
import org.apache.spark.sql.types._

val array = for (i <- List.range(1, 1000)) yield Row(i, i % 2)
val schema = StructType(StructField("id1", IntegerType, true) :: StructField("value1", IntegerType, true) :: Nil)
val df1 = spark.createDataFrame(sc.parallelize(array, 50), schema)

val array2 = for (i <- List.range(1, 5000)) yield Row(i, i % 3)
val schema2 = StructType(StructField("id2", IntegerType, true) :: StructField("value2", IntegerType, true) :: Nil)
val df2 = spark.createDataFrame(sc.parallelize(array2, 50), schema2)

// ---
df1.createOrReplaceTempView("t1")
df2.createOrReplaceTempView("t2")
// ---

// Q.1 : 
val res1 = spark.sql("SELECT * FROM t1 JOIN t2 ON t1.id1 = t2.id2")
res1.collect()
res1.explain
// InitPlan : par défaut -> SortMergeJoin
// FinalPlan : après intervention de l'AQE lors du collect -> BroadcastHashJoin sur t1

// Q.2 :
val res2 = spark.sql("SELECT /*+ BROADCAST(t1) */ * FROM t1 JOIN t2 ON t1.id1 = t2.id2")
res2.explain()
// Plan : BroadcastHashJoin

// Q.3 :
val res3 = df1.join(broadcast(df2), df1("id1") === df2("id2"))
res3.explain()
// Plan : BroadcastHahJoin
// Inversé par rapport à Q2
// Q2 Plan : BroadcastHahJoin BuildLeft
// Q3 Plan : BroadcastHashJoin BuildRight

// Q.4 :
val res4 = df1.hint("MERGE").join(df2, df1("id1") === df2("id2"))
res4.explain()
// Plan : SortMergeJoin

// Q.5
val res5 = spark.sql("SELECT /*+ SHUFFLE_HASH(t1) */ * FROM t1 JOIN t2 ON t1.id1 = t2.id2")
res5.explain()
// Plan : ShuffleHashJoin

// Q.6.a :
println(spark.sql("SELECT * FROM t1 JOIN t2 ON t1.id1 = t2.id2").rdd.partitions.length)
// 1

// Q.6.b :
val res6 = spark.sql("SELECT /*+ COALESCE(5) */ * FROM t1 JOIN t2 ON t1.id1 = t2.id2")
println(res6.rdd.partitions.length)
// 1


```
