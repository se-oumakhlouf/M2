# TP 10

</br>

```sh
# Q.0 :
bin/spark-shell --packages io.delta:delta-spark_2.12:3.2.0 \
    --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension" \
    --conf "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"
```

</br>

```scala
// Q.1 :
val df = spark.read.parquet("cisCompo")
```

</br>

```scala
// Q.2 :
df.write.format("delta").save("/tmp/test_delta")
```

</br>

```scala
// Q.3 :
val deltaDf = spark.read.format("delta").load("/tmp/test_delta")
deltaDf.schema
res4: org.apache.spark.sql.types.StructType = StructType(StructField(cis,IntegerType,true),StructField(forme,StringType,true),StructField(codeSub,IntegerType,true),StructField(nomSub,StringType,true),StructField(dosage,StringType,true),StructField(ref,StringType,true),StructField(nature,StringType,true),StructField(liaison,IntegerType,true))
```

</br>

```scala
// Q.4 :
deltaDf.count
Long = 32561
```

</br>

```scala
// Q.5 :
deltaDf.printSchema()

root
 |-- cis: integer (nullable = true)
 |-- forme: string (nullable = true)
 |-- codeSub: integer (nullable = true)
 |-- nomSub: string (nullable = true)
 |-- dosage: string (nullable = true)
 |-- ref: string (nullable = true)
 |-- nature: string (nullable = true)
 |-- liaison: integer (nullable = true)
```

</br>

```scala
// Q.6 :
val df1Updated = df.withColumn("codeSub", 
    when(col("codeSub") === 19745, 19754)
    .otherwise(col("codeSub"))
)
```

</br>

```scala
// Q.7 :
import io.delta.tables._
val deltaTable = DeltaTable.forPath(spark, "/tmp/test_delta")

deltaTable.update(
  col("codeSub") === 19745,
  Map("codeSub" -> lit(19754))
)
```

</br>

```scala
// Q.8 :
deltaTable.delete(col("cis") === 60259993)

deltaTable.toDF.filter(col("cis") === 60259993).show()
```
