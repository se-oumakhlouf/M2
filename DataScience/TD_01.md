```scala
// Code du cours 

val trainDF = spark.read.parquet("mlDatasets/trainDFfull")
val testDF = spark.read.parquet("mlDatasets/testDFfull")

trainDF.select("neighbourhood_cleansed", "room_type", "bedrooms", "bathrooms", "number_of_reviews", "price").show(5)

// +----------------------+---------------+--------+---------+-----------------+-----+
// |neighbourhood_cleansed|      room_type|bedrooms|bathrooms|number_of_reviews|price|
// +----------------------+---------------+--------+---------+-----------------+-----+
// |       Diamond Heights|   Private room|     1.0|      1.0|              1.0|200.0|
// |               Bayview|Entire home/apt|     1.0|      1.0|             13.0|130.0|
// |               Bayview|Entire home/apt|     1.0|      1.0|             12.0| 95.0|
// |               Bayview|Entire home/apt|     1.0|      1.0|              1.0|250.0|
// |               Bayview|Entire home/apt|     3.0|      3.0|              0.0|250.0|
// +----------------------+---------------+--------+---------+-----------------+-----+


println(f"""There are ${trainDF.count} rows in the training set, and ${testDF.count} in the test set""")
// There are 5780 rows in the training set, and 1366 in the test set

import org.apache.spark.ml.feature.VectorAssembler
val vecAssembler = new VectorAssembler().setInputCols(Array("bedrooms")).setOutputCol("features")
val vecTrainDF = vecAssembler.transform(trainDF)

import org.apache.spark.ml.regression.LinearRegression
val lr = new LinearRegression().setFeaturesCol("features").setLabelCol("price")
val lrModel = lr.fit(vecTrainDF)

val m = lrModel.coefficients(0)
// m: Double = 123.6757463819947
val b = lrModel.intercept
// b: Double = 47.51023373378815

println(f"""The formula for the linear regression line is price = $m%1.2f*bedrooms + $b%1.2f""")
// The formula for the linear regression line is price = 123.68*bedrooms + 47.51

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(vecAssembler, lr))
val pipelineModel = pipeline.fit(trainDF)
val predDF = pipelineModel.transform(testDF)
predDF.select("bedrooms", "features", "price", "prediction").show(10)

// +--------+--------+------+------------------+
// |bedrooms|features| price|        prediction|
// +--------+--------+------+------------------+
// |     1.0|   [1.0]|  85.0|171.18598011578285|
// |     1.0|   [1.0]|  45.0|171.18598011578285|
// |     1.0|   [1.0]|  70.0|171.18598011578285|
// |     1.0|   [1.0]| 128.0|171.18598011578285|
// |     1.0|   [1.0]| 159.0|171.18598011578285|
// |     2.0|   [2.0]| 250.0|294.86172649777757|
// |     1.0|   [1.0]|  99.0|171.18598011578285|
// |     1.0|   [1.0]|  95.0|171.18598011578285|
// |     1.0|   [1.0]| 100.0|171.18598011578285|
// |     1.0|   [1.0]|2010.0|171.18598011578285|
// +--------+--------+------+------------------+
```

</br>

```scala
// Q1 : 
import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder}
import org.apache.spark.ml.evaluation.RegressionEvaluator

val indexer = new StringIndexer().setInputCol("cancellation_policy").setOutputCol("cancellation_policy_indexed")

val encoder = new OneHotEncoder().setInputCol("cancellation_policy_indexed").setOutputCol("cancellation_policy_vec")

val vecAssembler = new VectorAssembler().setInputCols(Array("bedrooms", "cancellation_policy_vec")).setOutputCol("features")

val lr = new LinearRegression().setFeaturesCol("features").setLabelCol("price")

val pipeline = new Pipeline().setStages(Array(indexer, encoder, vecAssembler, lr))
val pipelineModel = pipeline.fit(trainDF)
val predDF = pipelineModel.transform(testDF)

val evaluator = new RegressionEvaluator().setLabelCol("price").setPredictionCol("prediction").setMetricName("r2")

val r2 = evaluator.evaluate(predDF)
println(f"La valeur de la métrique R2 est : $r2%1.4f")
// La valeur de la métrique R2 est : 0.1316

```